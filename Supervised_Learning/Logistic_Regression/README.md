# Logistic Regression

## Introduction
This Jupyter notebook explores the implementation and application of Logistic Regression, a statistical method extensively used in machine learning for binary classification problems. The notebook covers the theory behind Logistic Regression, detailing the logistic function, the concept of Binary Cross Entropy Loss, and the application of Gradient Descent for optimization.

## Contents
1. **Logistic Regression Theory**
   - Introduction to Logistic Regression
   - The Logistic Function
   - Linear Combination of Input Features
2. **Binary Cross Entropy (BCE) Loss Function**
   - Likelihood Function
   - Log-Likelihood
   - Negative Log-Likelihood
   - Binary Cross Entropy Loss Function
3. **Gradient Descent**
   - Derivative of BCE
   - Implementation of Stochastic Gradient Descent (SGD)
4. **Data Implementation**
   - Data Visualization and Standardization
   - Dataset Description
   - Data Preprocessing Steps

## Implementation
The notebook demonstrates the implementation of Logistic Regression using a publicly accessible dataset from the Framingham Heart Study. This dataset aims to forecast the 10-year risk of coronary heart disease (CHD) and contains more than 4,000 entries with 15 different attributes.

Key components of the implementation include:
- Sigmoid function for probability estimation.
- Calculation of Binary Cross Entropy Loss.
- Stochastic Gradient Descent for model optimization.

## Visualization
The notebook includes visualization of the loss reduction over iterations, demonstrating the efficacy of the implemented logistic regression model.

## Conclusion
The final section summarizes the content in this jupyter notebook of Logistic Regression.
